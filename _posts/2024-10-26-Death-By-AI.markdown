---
layout: post
title:  "Death By AI"
date:   2024-10-26 00:00:22 -0400
categories: jekyll update
---
 
Short History of AI
----

 AI stands for Artificial Intelligence. It is humans effort to create intelligence in electronic or silicon frameboards. It carries the name artificial as it is man made and is seperate from the creations of nature. Though the history of AI is thousand years old [1], the modern AI has it roots in 20th century. In 1956, a group of scientist (which included heavy weights in the field as Marvin Minksy, John McCarthy and Claude Shannon) who conceived a new field as "artificial Intelligence." There premise was to create thinking machines and discover the scientific basis of thought, mind and computation process of the brain. Earlier then the Darmouth meeting, was the collaborative work of Warren McCulloch (MIT Professor) and Walter Pitts, which set the basis of the neural network as we presently know of [2]. The MIT researchers were influenced by the ideas of Gottfried Leibniz, who stated that thoughts were an outcome of seperate components which were combined together to create concepts and facts and with the mixture of logical rules, all of human knowlegde can be produced. Further, McCulloch was a doctor by profession and saw the human brain as nothing different then a computing machine. As such all thoughts are computable. The neural network was an outcome of reverse-engineering the working of the brain neurons and synapses and the intriguing quality of neurons to be binary, as it sends or don't send an electrical signal. 
                                               
 In 1969, the Minsky XOR problem was published [3]. It stated that a single-layer perceptron (the simplest neural network) is unable to solve the XOR problem (give true output of the two parameters of an input are similar, else it gives false output). This innocouous problem proved to be devastating to the AI field and it caused the AI- winter to set in. It took decades to realize that a multi-layer perceptron can potentially solve the Minsky's problem. Another theorem that brought resurgence of AI was `backpropagation algorithm`, which allows the neural weights to be adjusted in relation to the error that is accumulated on the predictions [4]. Faster computing power with the advent of GPU (General Processing Unit) and the emergence of large data sets has allowed the widespread adoption of neural network or machine learning technologies. In my personal experience, the advent of faster computer or online clusters and the open-source data sets has been a game-changer. A recent invention of the `Transformers` have become staple in order to make learning models work faster and better in all AI-applications [5]. 


AGI
----






References
----------------

[1] Peter Norvig, Artificial Intelligence: A Modern Approach, 2004

[2] https://nautil.us/the-man-who-tried-to-redeem-the-world-with-logic-235253/

[3] Marvin Minsky and Seymour A. Papert, Perceptrons: An Introduction to Computational Geometry, 1969

[4] Paul J. Werbos,  The Roots of Backpropagation : From Ordered Derivatives to Neural Networks and Political Forecasting, 1994

[5] Ashish Vaswani, Attention Is All You Need, 2017